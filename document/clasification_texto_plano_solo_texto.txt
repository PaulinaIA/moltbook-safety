Autor: Paulina Peralta • Fecha: 24 Jan 2026

Objetivo: Clasificación binaria de Pokémones legendarios.

- Imports y carga de datos
- EDA
  - Estudio general de los datos
  - Variables Numéricas
    - Histogramas
    - Boxplots
    - Test de Normalidad Shapiro-Wilk
  - Variables categóricas
    - rank
    - type1
    - type2
    - type1 + type2
    - generation
    - evolvesfrom
  - Análisis de las variables objetivos para la clasificación
    - Variable binaria
      - Distribución y desbalance de clases
      - Relación con variables numéricas
        - Test de Mann-Whitney
      - Relación con variables categóricas
        - Test Chi-cuadrado
- Procesado de los datos
  - Codificación de variables categóricas
  - Creación de variable hastype2
  - Feature Engineering
  - Preparación del dataset final
  - Estandarización de los datos
  - Análisis de multicolinealidad
  - Importancia de características
  - División Train-Test y SMOTE
- Modelos de Clasificación
  - Regresión Logística
  - SVM
  - Árbol de Decisión
  - KNN
- Evaluación y Comparativa de Modelos
  - Matrices de Confusión
  - Curvas ROC
  - Comparativa Final
- Conclusiones

En este cuaderno entrenaremos varios modelos de clasificación, para descubrir si con los datos de una “Pokédex” podemos predecir la categoría de un Pokémon.

El dataset utilizado es “Data of 1015 Pokémons” de Kaggle, que funciona como una Pokédex estructurada, el cual influye información de 1025 Pokémons con variables de identidad, tipos, estadísticas de combate, rasgos y extras.

- id — número de Pokédex
- name — nombre del Pokémon
- rank — rareza/categoría (ordinary, legendary, mythical, sub-legendary, etc.)
- generation — región/generación (generation-i, generation-ii, …)
- evolvesfrom — evolución previa

- type1 — tipo principal
- type2 — tipo secundario (puede ser None)

- hp, atk, def, spatk, spdef, speed — estadísticas base
- total — suma total de stats

- height, weight — medidas físicas
- abilities — habilidades
- desc — descripción Pokédex

Se importan las librerías necesarias para el análisis exploratorio, el preprocesamiento de los datos y la clasificación.

Defino colores de Pokémon para que el análisis sea representativo.

Se utiliza kagglehub para descargar el dataset de Pokémon y pandas para cargarlo.

Se carga el dataset utilizando pandas con la función readcsv.

En el Análisis Exploratorio de los datos, haremos un estudio exaustivo de los mismos para entender en profundidad que contienen, cual es su distribución, cual es su tamaño, cual es el tipo de dato y todas las características posibles para entenderlos, y lograr clasificar Pokémons de forma óptima.

Se visualiza las 5 primeras filas del dataset.

Se visualiza las 5 últimas filas del dataset.

Visualizamos la información completa del dataset.

Visualizamos las estadísticas descriptivas de las variables numéricas.

Se visualiza el tamaño del dataset.

Se visualiza el tipo dato por cada columna que tiene el dataset.

Se visualizan los distintos valores que tiene la variable rank.

Sumamos todos los valores de cada fila de la tabla.

Se visualizan los distintos valores que tiene la variable type1.

Sumamos todos los valores de cada fila de la tabla.

Se visualizan los distintos valores que tiene la variable generation.

Se verifica si las columnas contienen nulls. Para ello se creo un bucle for con el cual se recorren todas las columnas del dataset en el cual por cada columna se hace una sumatoria de los nulls si es que contiene alguno y se imprime.

En un primer vistazo se visualiza que la columna "type2" contiene 499 nulls. Esto se debe a que son Pokémons monotipo, lo cual significa que poseen un único tipo. Para solucionar eso lo que hacemos es remplazar el valor faltante por monotype, para poder realizar el análisis completo.

Luego visualizamos el cambio.

Y verificamos que no haya filas duplicadas en el dataset.

Separamos y analizamos las variables numéricas del dataset, que serán las principales features para nuestros modelos de clasificación.

Verificamos si existen valores nulos.

No se observan valores nulos en las variables numéricas.

A continuación visualizamos las estadísticas descriptivas de las variables numéricas.

Visualizamos la distribución de las estadísticas de combate (hp, atk, def, spatk, spdef, speed) mediante histogramas.

Se observa que:

- HP (Puntos de Salud): tiene una asimetría positiva con un pico aproximadamente en 70 que coincide con la media de 70.2. La mayoría de los Pokémon tienen HP entre 40 y 100 aproximadamente. Se visualiza una cola hacia la derecha con algunos Pokémon que tienen HP superiores a 150, con valores de hasta 250 que probablemente sean Pokémons legendarios o formas especiales.

- ATK (Ataque): tiene una distribución con un asimetría positiva y un pico cerca de 75 y media de 77.5. La mayoría de los Pokémon tienen ataque entre 50 y 100 aproximadamente. Se visualiza una cola hacia la derecha con valores que llegan hasta 175 aproximadamente, lo cual indica que existen algunos Pokémons con estadísticas de ataque mayores al promedio.

- DEF (Defensa): tiene una asimetría positiva con un pico aproximadamente en 70 y una media de 72.5. Y se visualiza que la mayoría de los Pokémons tienen una defensa entre 40 y 100 aproximadamente. Se observan muchos valores atípicos hacia la derecha que llegan hasta 200 aproximadamente, que indica que hay Pokémons muy defensivos.

- SPATK (Ataque Especial): tiene una distribución con asimetría positiva con un pico cercano a 65 y una media de 70.1. Entre 30 y 80 es el ataque especial que tienen la mayoría de los Pokémons, luego hay algunos que tienen más que se visualiza en la cola hacia la derecha que llega hasta 180 aproximadamente, ahí están los Pokémons que tienen poderes especiales y muy avanzados, del tipo psíquico o dragón.

- SPDEF (Defensa Especial): la defensa especial tiene una distribución asimétrica positiva con una cola a la derecha, un pico en 65 aproximadamente y una media de 70.2. La defensa especial de los Pokémons en suelen estar entre 40 y 90 aproximadamente. Habiendo muy pocos que superan 150, que probablemente son los legendarios o del tipo hada o psíquico con defensas especiales.

- SPEED (Velocidad): tiene una asimetría positiva con un pico cercano a la media en 67.2. La mayoría de los Pokémons tienen una velocidad de entre 30 y 100 aproximadamente. Se visualiza una cola hacia la derecha con valores que superan 150, los cuales probablemente se trate de Pokémons legendarios.

En general, todas las estadísticas de combate siguen distribuciones similares con asimetría positiva, donde la mayoría de los Pokémon tienen valores cercanos a la media para todas las estadísticas, y los valores extremos hacia la derecha parecen tener relación con Pokémons legendarios, míticos o formas especiales que tienen estadísticas superiores al promedio. Lo cual es interesante porque en las distribuciones se visualizan patrones que nos ayudaran a clasificarlos.

Para entender mejor la distribución de las estadísticas de combate y visualizar los valores atípicos, realizamos gráficos de boxplots de cada una de las estadísticas (hp, atk, def, spatk, spdef, speed).

Se observa que:

- HP (Puntos de Salud): el IQR está entre aproximadamente 50 y 90, con una mediana cerca de 70. Se visualizan varios outliers hacia la derecha con valores que superan los 150, llegando hasta 250 aproximadamente, los cuales probablemente correspondan a Pokémons legendarios o formas especiales con estadísticas excepcionales.

- ATK (Ataque): el IQR se encuentra entre aproximadamente 55 y 100, con una mediana cerca de 75. Se observan outliers hacia la derecha con valores que superan los 150, llegando hasta 175 aproximadamente, lo cual indica la presencia de Pokémons con capacidades de ataque físico muy superiores al promedio.

- DEF (Defensa): el IQR está entre aproximadamente 50 y 90, con una mediana cerca de 70. Se visualizan muchos outliers hacia la derecha con valores que superan los 150, llegando hasta 200 aproximadamente, lo cual indica que existen Pokémons con defensas físicas excepcionales, probablemente del tipo roca, acero o formas defensivas especiales.

- SPATK (Ataque Especial): el IQR se encuentra entre aproximadamente 45 y 90, con una mediana cerca de 65. Se observan outliers hacia la derecha con valores que superan los 130, llegando hasta 180 aproximadamente, los cuales probablemente correspondan a Pokémons del tipo psíquico, dragón o con poderes especiales muy avanzados.

- SPDEF (Defensa Especial): el IQR está entre aproximadamente 50 y 90, con una mediana cerca de 70. Se visualizan algunos outliers hacia la derecha con valores que superan los 150, aunque en menor cantidad que en otras estadísticas, los cuales probablemente sean Pokémons legendarios o del tipo hada o psíquico con defensas especiales excepcionales.

- SPEED (Velocidad): el IQR se encuentra entre aproximadamente 45 y 90, con una mediana cerca de 67. Se observan outliers hacia la derecha con valores que superan los 130, llegando hasta 150 aproximadamente, los cuales probablemente se traten de Pokémons legendarios o del tipo eléctrico con velocidades excepcionales.

En general, todas las estadísticas de combate presentan distribuciones con asimetría positiva, donde el 50% de los Pokémon se concentra en el rango del IQR alrededor de la mediana, y los outliers hacia la derecha parecen estar relacionados con Pokémons legendarios, míticos o formas especiales que tienen estadísticas superiores al promedio. Lo cual también se visualizó en los histogramas, por lo tanto da a entender que representa a un grupo de Pokémons lo cual consideramos que será útil para la clasificación.

Para entender mejor la distribución antes del modelado hacemos el test de normalidad de Shapiro-Wilk que verifica si una muestra proviene de una distribución normal. Para ello hacemos dos hipótesis:

- H₀ (Hipótesis nula): Los datos siguen una distribución normal
- H₁ (Hipótesis alternativa): Los datos NO siguen una distribución normal

Si el test de Shapiro-Wilk es cercano a 1, la distribución es más compatible con la normalidad y si es cercano a cero es menos compativle con la normalidad.

Por lo cual, si:
- p > 0.05: No se rechaza la hipótesis nula, ya que no podemos asumir normalidad.
- p ≤ 0.05: Se rechaza la hipótesis nula.

Para todas las variables el p-valor del test de Shapiro-Wilk es 0.05<, por lo tanto no se cumple el supuesto de normalidad, entonces rechazamos la hipótesis nula. Lo cual coincide con lo que hemos visualizado en los histogramas y boxplots. Para la clasificación con los algoritmos que utilizaremos no es un requisito que las distribuciones sean normales.

Separamos y visualizamos las variables categóricas del dataset.

La variable rank indíca especialmente la rareza del Pokémon para visualizar su distribución primero contamos la frecuencia por tipo.

Graficamos la distribución de Pokémones por rank.

913 Pokémons son ordinary, es decir comunes y capturables normalmente. 70 son legendary, es decir muy raros y poderosos. 23 son mythical que significa que son aún más raros y 19 son babys pre evolucionados, es decir formas anteriores de un Pokémon antes de evolucionar. Para la clasificación debemos tener en cuenta este desbalance de clases que se visualiza en la distribución de rank.

La variable type1 indica el tipo principal de Pokémon, que suele determinar ciertas fortalezas y debilidades en el combate, también puede influir en las estadísticas. Por ello primero contamos los tipos que hay en el dataset.

Y graficamos la distribución de Pokémones por type1.

En la distribución se visualiza que los tipos más comúnes de Pokémons son water, normal y grass. Lo que da a enteder que hay muchos Pokémones en ecosistemas acuaticos, muchos comúnes y muchos de bosques y naturaleza, lo cual tiene sentido incluso si comparamos con la gráfica de rank, pero para ir más a profundidad debemos estudiar todas las variables primero.

Así también, los menos comúnes fueron ice, fairy y flying que suelen ser de tipos especializados o en algunos casos con ecosistemas más dificiles de acceder. Aunque flying es más común en el type2, suele ser raro que aparezca en el type1 ya que la mayoría de los Pokémones que son voladores suelen tener otro tipo como base por ejemplo: normal, fire, water, entre otros.

Exsiten algunos Pokémons que tiene type2, que no necesariamente significa que tengan mejores estadísticas sino que tienen más combinaciones de fortalezas o debilidades. A continuación veremos su distribución, pero primero contamos la frecuencia de los tipos en el dataset.

Y graficamos la distribución de Pokémones por type2.

En la distribución por type2 aparecen 499 Pokémones que no tienen tipo secundario, y luego 100 Pokémones muchos mayor al promedio que tienen flying. Y los types2 menos comunes son normal, electric y bug, los cuales suelen ser más comunes como type1.

Para comprender mejor los patrones debido a los tipos. Decidimos hacer una combinacion de ambos para entender a los Pokémons dualtypes.

Y graficamos el top 15 de combinaciones dual-type más comunes en el dataset sin monotype.

La combinación más comun es normal+flying lo cual tiene sentido ya que analizando los gráficos anteriores donde normal era el segundo type1 con mayor frecuencia en el dataset y flying el que tiene más frecuencia en type2, tiene sentido que sea la combinación dual más frecuente.

Luego grass + poisson también tiene sentido en primer lugar por el ecosistema y también por la frecuencia que aparecen en type1 y type2.

En general se visualiza que las combinaciones dual-type tienen una especia de patrón de acuerdo al escosistema por ejemplo: grass+poison, bug+flying, water+ground, rock+watert, etc. Aunque algúnos parecen más raros como psychic+flying, water+flying, etc.

Para visualizar mejor las combinaciones, creamos una matriz excluyendo monotype.

En esta matriz se visualiza las combinaciones más comúnes como mencionamos antes en el gráfico de barras, pero lo más interesante es si visualizamos las filas y columnas por ejemplo en la fila de flying es notorio que esta tiene más combinaciones, lo que nos da a entender que la mayoría de Pokémones duales se combinan con flying siendo la combinación más común normal+flying. Asi también si miramos la fila de flying la veremos con muy pocos valores lo que refuerza el hecho de que es más común como type2.

Parece existir como vimos en la distribución anterior patrones debido a la naturaleza o por estrategía, por ejemplo: dark+gragon,grass+dark,bug+poison, etc.

Y por último lo más cursioso es que realmente si tenemos en cuenta todo el dataset son menos el grupo de Pokémones dual-type, con algunas combinaciones mucho más comúnes que otras. Lo cual indica un desbalanceo de clases en esta combinación que podría ser un factor importante para hacer la clasificación.

La variable generation es interesante para el análisis ya que indica en cual generación de los videojuegos fue introducido cada Pokémon por ejemplo:

Otro factor importante a tener en cuenta para el análisis es que cada generación aparte de introducir nuevos Pokémons, también introduce regiones geográficas, nuevos tipos o mecánicas de juego.

Por ello en primer lugar contamos y ordenamos las generaciones para analizar si hay algún patrón entre los pokémones según la generación.

Y las graficamos en un gráfico de barras para ver mejor la cantidad y en un gráfico circular para ver mejor los porcentajes.

Es interesante porque al parecer en algunas generaciones hay más pokémones que en otras. Las generaciones con mayor cantidad de pokémones son la Gen 1, Gen 3 y Gen 5. Luego las generaciones con menor cantidad son la generación 6, 7 y 8.

A continuación veremos como los type1 más comúnes se distribuyen en estas generaciones para ver si encontramos un patrón. Para ello seleccionamos los tops 6 de type1, es decir los más frecuentes, filtramos esos nombres del dataset, creamos una tabla matricial entre generation y type1, y luego lo reordenamos para que aparezca en orden cronológico.

En la Generación 1 fue donde se introdujeron más Pokémones comúnes del type1 siendo el más abundante del tipo water y normal, seguido por la generación 5 con bug, water y normal. Lo curioso de la generación 5 es que se introdujeron más type1 comúnes en general.

A lo largo de las generaciones también se ve un patrón, como a medida que pasaba el tiempo se introducían menos water y normal y más grass por ejemplo. En cambio fire siempre se introdujo de 5 a 12 por generación.

El que me llama mucho la atención es psychic, el cual en la generación 5 tuvo un pico de Pokémons que se introdujeron y en la generación 9 solo 2, siento la menor introducción de Pokémons en toda la matriz.

En esta categoría también se visualiza un desbalance de clases por generación que hay que tener en cuenta para el análisis.

La variable evolvesfrom indica de que Pokémon evoluciona cada Pokémon en el dataset, donde un Pokémon puede ser de una forma base, es decir nothing o evolucionar a otro Pokémon. A continuación se muestran ejemplos.

Generalmente los Pokémones evolucionados mejoran sus estadísticas a excepcion de algunos que no evolucionan como por ejemplo Mewtwo que es un Pokémon legendario. Para analizarlos mejor cree una variable binaria de evolución.

Y cree una funcion que determina la etaá evolucitva del Pokémon, para verificar si el Pokémon del que evoluciona, tiene una evolución también.

Luego contamos la evolucion y los stages.

Y gráficamos la distribución de los Pokémons por estado de evolución, es decir si evolucionano no.

Se visualiza que la mayoría de los Pokémons no evolucionan con un 52.8% sobre un 47.2% que si lo hacen, en esta distribución podrían estar pokémons raros que no evolucioan. A continuación para visualizar mejor grafico la distribución por etapa evolutiva y rango, de manera a entender la distribución de acuerdo a otras categorías también.

Entre los Pokémons que evolucionan un 35.4% va al Stage 2 y solo un 11.8% al Stage 3. Si visualizamos por rangos vemos que la mayoría de los Pokémons que evolucionan son ordinary mientras que los babys mythical y legenday suelen estar el la etapa evolutiva de base.

Graficamos un boxplot y violinplot para visualizar el total de las estadísticas de combate según la etapa evolutiva.

La etapa Base tiene una mediana aproximadamente en 320 y un IQR entre aproximadamente 300 y 490, lo cual es esperado ya que en esta etapa se encuentran tanto Pokémons comunes como algunos legendarios o míticos que no evolucionan, como Mewtwo o los Pokémons bebé. La etapa Stage 2 tiene una distribución más concentrada con una mediana aproximadamente en 450 y un IQR entre aproximadamente 410 y 490, mientras que la etapa Stage 3 tiene una distribución más simétrica y concentrada con una mediana aproximadamente en 520 y un IQR entre aproximadamente 500 y 550.

En general, se visualiza una tendencia donde las estadísticas totales aumentan con cada etapa evolutiva, lo cual es consistente con la mecánica del juego donde los Pokémons evolucionados son más poderosos, donde la variabilidad disminuye a medida que se avanza en las etapas evolutivas, sugiriendo que los Pokémons en etapas más avanzadas tienen estadísticas más predecibles y concentradas alrededor de la mediana. Esta relación entre etapa evolutiva y estadísticas totales es interesante de analizar ya que para hacer una clasificación multiclase la etapa evolutiva puede ser una variable predictora interesante.

Luego del análisis exploratorio de las variables numéricas y categóricas, considerando el objetivo de este proyecto que es realizar una clasificación binaria y de multiclase, hemos de definir las variables objetivos.

Para la clasificación binaria se ha identificado una característica muy importante en los Pokémones que es si son legendarios o no. La analizaremos a fondo para ver si es óptima para el análisis.

Creamos una columna islegendary la cual identifica si un pokémon es legendario o no.

Se visualiza que 93 Pokémones son legendarios a diferencia de 932 que no lo son. Visualizamos el desbalance de clases.

Se visualiza un desbalance significativo entre las clases, donde los Pokémones Orginarios representan aproximadamente el 90% del dataset, que se tendra en cuenta a la hora de entrenar los modelos.

Para visualizar cuales variables podrían ser más predictivas graficamos una distribución comparando las medias de las estadísticas si islegendary es 1 o 0.

Los legendarios tienen de media valores más altos en sus estadísticas que los no legendario, para visualizar mejor sus distribuciones realicé una gráfica comparativa de los mismos.

- TOTAL: los ordinarios tienen un pico en 500 aproximadamente, donde la mayoría se concentra entre 300 y 550. Los legendarios tienen una distribución desplazada hacia valores más altos, con picos alrededor de 550. Se visualiza que casi todos los legendarios superan los 500 puntos totales, mientras que la mayoría de los ordinarios están por debajo de este umbral. Esta variable muestra la mayor capacidad discriminativa entre ambas clases.

- HP: los ordinarios tienen un máximo en 75-100 aproximadamente y la mayoría se concentra entre 40 y 120. Los legendarios muestran una distribución más dispersa pero desplazada hacia valores superiores lo cual tiene sentido, con valores encima de 100 HP y en algunos casos hasta 250 aproximadamente.

- ATK: la distribución de los ordinarios tiene un pico en 75 aproximadamente, de los cuales la mayoría se encuentra entre 50 y 120 aproximadamente. Los legendarios en cambio tienen valores más altos, con una mayor frecuencia en rangos superiores a 100 hasta 175 aproximadamente.

- DEF: similar al ataque, los ordinarios se concentran alrededor de 75-100 DEF, mientras que los legendarios muestran una distribución desplazada hacia valores superiores, con casos extremos que alcanzan hasta 200 aproximadamente. Se observa que la diferencia es clara, especialmente en los valores más altos donde prácticamente solo aparecen legendarios, lo cual probablemente corresponda a Pokémons del tipo roca, acero o formas defensivas especiales.

- SPATK: los ordinarios tienen un pico en 75 aproximadamente, donde la mayoría se encuentra entre 50 y 120 aproximadamente. Los legendarios muestran una distribución claramente superior, con mayor frecuencia en rangos superiores a 100 hasta 180 aproximadamente. Esta estadística muestra una de las mayores diferencias entre clases, siendo especialmente útil para identificar legendarios, ahí están los Pokémons que tienen poderes especiales y muy avanzados, del tipo psíquico o dragón.

- SPDEF: la distribución de los ordinarios tiene un pico en 75 aproximadamente, donde la mayoría se encuentra entre 40 y 90 aproximadamente. Los legendarios en cambio tienen valores más altos, con presencia notable por encima de 100 hasta 200 aproximadamente. Aunque hay solapamiento en el rango medio, los valores extremos son característicos de legendarios, que probablemente sean del tipo hada o psíquico con defensas especiales.

- SPEED: los ordinarios tienen un pico en 75 aproximadamente, donde la mayoría se encuentra entre 50 y 120 aproximadamente. Los legendarios muestran una distribución desplazada hacia valores superiores, con mayor frecuencia por encima de 100 hasta 200 aproximadamente. Se visualiza que la velocidad es una variable predictiva útil, especialmente para identificar legendarios, los cuales probablemente se trate de Pokémons del tipo eléctrico o volador.

- HEIGHT: ambas clases muestran una concentración muy alta en valores bajos entre 0 y 25 aproximadamente, pero los legendarios presentan una distribución más dispersa con algunos casos en rangos medios y altos entre 100 y 150 aproximadamente, donde los ordinarios son prácticamente inexistentes.

- WEIGHT: similar a la altura, ambas clases se concentran en valores bajos entre 0 y 1000 aproximadamente, pero los legendarios muestran una cola más extendida hacia valores superiores, con casos que alcanzan 4000-6000 aproximadamente donde los ordinarios son prácticamente inexistentes.

En general, todas las estadísticas de combate (TOTAL, HP, ATK, DEF, SPATK, SPDEF, SPEED) muestran distribuciones diferentes entre ordinarios y legendarios, los legendarios desplazados hacia valores superiores. El TOTAL muestra la mayor capacidad discriminativa, seguido de SPATK y SPDEF. Las variables físicas (HEIGHT, WEIGHT) tienen menor capacidad discriminativa en general, pero los valores extremos pueden ser indicativos de legendarios. Lo cual es interesante porque en las distribuciones se visualizan patrones que nos ayudarán a clasificarlos, ya que estas diferencias confirman que las estadísticas de combate son variables altamente predictivas para la clasificación binaria entre Pokémons ordinarios y legendarios.

- HP: los ordinarios tienen una mediana alrededor de 75, con un IQR entre aproximadamente 50 y 100. Los legendarios tienen una mediana más alta alrededor de 95, con un IQR más compacto entre aproximadamente 80 y 100. Se visualizan varios outliers por encima de 150, llegando hasta 250 aproximadamente, los cuales probablemente correspondan a Pokémons legendarios o formas especiales.

- ATK: los ordinarios tienen una mediana alrededor de 75, con un IQR entre aproximadamente 50 y 95. Los legendarios muestran una mediana más alta alrededor de 100, con un IQR entre aproximadamente 85 y 120. Se observa una clara tendencia de los legendarios hacia valores de ataque más altos, lo cual tiene sentido ya que los Pokémons legendarios suelen tener estadísticas superiores.

- DEF: los ordinarios tienen una mediana alrededor de 55, con un IQR entre aproximadamente 40 y 85. Los legendarios tienen una mediana más alta alrededor de 95, con un IQR más compacto entre aproximadamente 80 y 110. Se visualiza que los legendarios exhiben valores de defensa sustancialmente más altos, lo cual probablemente corresponda a Pokémons del tipo roca, acero o formas defensivas especiales.

- SPATK : los ordinarios tienen una mediana alrededor de 60, con un IQR entre aproximadamente 45 y 85. Los legendarios muestran una mediana más alta alrededor de 100, con un IQR entre aproximadamente 80 y 130. Se observa una fuerte tendencia de los legendarios hacia valores de ataque especial mucho más altos, ahí están los Pokémons que tienen poderes especiales y muy avanzados, del tipo psíquico o dragón.

- SPDEF: los ordinarios tienen una mediana alrededor de 65, con un IQR entre aproximadamente 50 y 80. Los legendarios tienen una mediana más alta alrededor de 95, con un IQR entre aproximadamente 80 y 115. Los legendarios generalmente poseen valores de defensa especial más altos, que probablemente sean los legendarios o del tipo hada o psíquico con defensas especiales.

- SPEED: los ordinarios tienen una mediana alrededor de 60, con un IQR entre aproximadamente 45 y 80. Los legendarios muestran una mediana más alta alrededor de 90, con un IQR más concentrado entre aproximadamente 80 y 110. Se observa que los legendarios tienden a tener valores de velocidad más altos, los cuales probablemente se trate de Pokémons legendarios del tipo eléctrico o volador.

En general, para todas las estadísticas de combate (HP, ATK, DEF, SPATK, SPDEF, SPEED), los legendarios muestran medianas más altas y tienen sus rangos intercuartílicos desplazados hacia valores superiores comparados con los ordinarios. Esta diferencia confirma lo que se observó en los histogramas y valida que las estadísticas de combate son variables altamente predictivas para la clasificación binaria entre Pokémons ordinarios y legendarios.

Se observa una diferencia muy marcada en las estadísticas totales entre Pokémons ordinarios y legendarios. Los legendarios tienen consistentemente valores de total más altos. La mediana de los Pokémons legendarios están alrededor de 600 y es superior a la de los ordinarios que está entre 420-430 aproximadamente. Aunque existe un pequeño solapamiento en las distribuciones, especialmente entre 500 y 550 aproximadamente, la mayoría de los Pokémons legendarios superan los 550 puntos totales, mientras que la mayoría de los ordinarios se encuentran por debajo de este umbral. Por lo tanto, podemos afirmar que la variable total muestra capacidad discriminativa para diferenciar entre Pokémons ordinarios y legendarios, lo cual es interesante porque en la distribución se visualizan patrones claros que nos ayudarán a clasificarlos.

A continuación realizamos el test de Mann-Whitney que es una prueba no paramétrica que compara dos grupos independientes, para poder determinar si hay o no diferencia entre las distribuciones, donde:

- H0: No hay diferencia entre las distribuciones
- H1: Hay diferencia significativa

Para todas las estadísticas de combate el p-value es menor a 0.05 por lo tanto se rechaza la hipótesis nula y asumimos que hay una diferencia significativa entre las distribuciones, confirmando que las distribuciones entre Pokémons ordinarios y legendarios son estadísticamente diferentes. Lo cual confirma lo que visualizó en los histogramas superpuestos, boxplots y violin plots que los Pokémones legendarios tienen estadísticas de combates superiores a los Pokémones ordinarios. Por lo tanto, todas las estadísticas de combate podrían ser variables útiles para la clasificación binaria entre Pokémons ordinarios y legendarios.

Comprobado que las distribuciones de las estadísticas de combates de los Pokémones son estadísticamente diferentes, analizamos ahora la relación entre la variable objetivo islegendary y las categorías. Para esto primero agrupamos islegendary por su proporción.

El tipo Psychic tiene la proporción más alta de legendarios, cercana a 0.30 aproximadamente, lo cual significa que casi el 30% de los Pokémons de tipo psíquico son legendarios. Le sigue el tipo Dragon con una proporción alrededor de 0.21-0.22 aproximadamente, y luego Steel con alrededor de 0.19. Los tipos Bug y Grass tienen las proporciones más bajas, por debajo de 0.05 aproximadamente. En cuanto a la cantidad absoluta, el tipo Water tiene la mayor cantidad total de Pokémons, pero la mayoría son ordinarios con muy pocos legendarios. El tipo Psychic, aunque tiene un total menor comparado con Water o Normal, muestra un número absoluto mayor de legendarios entre los top 10 tipos, lo cual tiene sentido porque tiene la proporción más alta de legendarios.

En general, se observa que hay una diferencia importante entre la proporción de legendarios y la cantidad absoluta: los tipos más comunes como Water, Normal, Grass y Bug tienen muchos Pokémons pero pocos legendarios, mientras que tipos como Psychic y Dragon tienen proporciones más altas de legendarios aunque menos Pokémons en total. Esta información es útil para la clasificación porque sugiere que el tipo principal puede ser una variable predictiva, especialmente para tipos como Psychic, Dragon y Steel que tienen proporciones más altas de legendarios.

Se visualiza que las generaciones más recientes como la VII y VIII, y la Generación IV, tienden a tener una mayor proporción y/o cantidad de Pokémons legendarios en comparación con las primeras generaciones, como la Generación I y II. Esta información es útil para la clasificación porque sugiere que la generación puede ser una variable predictiva, especialmente para identificar generaciones que tienen más probabilidad de contener Pokémons legendarios.

El test de chi-cuadrado se utiliza para testear la independencia de dos variables categóricas donde:

- H0: No hay asociacion entre las variables categóricas
- H1: Hay asociación entre las variables categóricas

Para ello definimos las variables categóricas que vamos a testear con islegendary:

Para type2 el p-value es mayor a 0.05 por lo tanto no se rechaza la hipótesis nula, en cambio para type1 y generation el p-value es menor a 0.05 por lo tanto para estas se rechaza la hipótesis nula y se asume mediante el test de chi-cuadrado que tiene una asociación significativa con la variable principal y que estas podrían ser variables predictivas para la clasificación entre Pokémones ordinarios y legendarios.

En la sección del procesado de los datos nos centraremos en análizar todas las variables, junto con la variable objetivo de forma a seleccionar las variables útiles para entrenar el clasificador con diferentes modelos y poder compararlos al final del proyecto. Por lo tanto, separamos las features numéricas y categóricas.

Para poder incluir las variables categóricas en el análisis debemos codificarlas, para ello utilizamos LabelEncoder que transforma etiquetas categóricas de texto en números enteros únicos.

Considerando que hay algunos pokémones que son monotipos, por lo tanto no tienen type2, el cual podría ser importante porque como vimos antes, muchos legendarios no suelen tener type2, por lo tanto es importante tener en cuenta esta variable el análisis. Para ello se creo una bariable binaria que tiene 0 si el pokémon es monotipo y tiene 1 si es un pokémon dual.

Para hacer un análisis completo he decidido crear features que aporten otro tipo de información teniendo como base la estadística de combate ya que como vimos en el apartado anterior en el ecosistema Pokémos suele haber un patrón entre las estadísticas y si es legendario o no.

Calculamos offensiveratio y defensiveratio que nos dice que porcentaje del total son stats de ataque.

Agregamos más features de estadísticas dada las features que tenemos. Estadísticas máximas y mínimas, un rango de estadísticas ya que los legendarios suelen ser más balanceados o tener un stat muy alto, la deviación estándard y el conteo de estadísticas superiores a 100.

También mejoramos features categóricas, ssobre si evoluciona o no en binario y sobre el si tiene o no el tipo secundario.

También incluimos features acerca del total por no evoluciona ya que los legendarios suelen tener estadísticas altas y no evolucionar.

Y una feature que convierte el valor total del cada Pokémon en su posición percentil dentro de todos los Pokémones del dataset.

Luego preparamos el dataset previo con el que analizaremos las features de manera a seleccionar las que nos van a ayudar a predecir mejor la clasificación. Para ello seleccionamos todas las variables numéricas excluyendo el id e islegendary que es la variable objetivo.

Luego estandarizamos los datos de forma a poder analizarlos en la misma escala.

Para estandarizar los datos se ha utilizado la función StardardScaler que nos proporciona Sklearn, ya que hemos visto que en este caso los outliers son esperados ya que asumimos que se deben a los legendarios y casos raros de la naturaleza del juego de Pokémon.

Para una correcta clasificación debemos analizar antes si hay variables con alta correlación, ya que si las hay podría haber multicolinealidad, que significa que las variables estan muy relacionadas entre sí, y hace que el modelo no pueda separar el efecto único de cada variable, generando coeficientes intestables y difíciles de interpretar. Para ello correlacionamos todas las features incluyendo a la variable objetivo y la graficamos en la matriz de correlación.

En la matriz de correlación se visualiza que la variable total es la más relacionada con islegendary la variable objetivo, la cual a su vez se encuentra bastante correlacionada con height y weight, a su vez height y weight tiene una correlacion super alta de 0.63, por lo cual estas variables podrían tener la misma información. Cabe destacar que la variable total es la sumatoria de las estadísticas de combate por esta razón también tiene una alta correlación con hp, atk, def, sspatk, spdef y speed, que también se refleja en menor medida con height y weight. Así también algunas variables de combate tambien están bastante correlacionadas entre sí, por ejemplo: hp+atk, def+atk, spdef+def, spatk+spdef, spatk+speed.

Las variables codificadas type1encoded, generationencoded y hastype2 no tienen mucha correlación con las demás variables lo que podría indicar que estas aportan otro tipo de información.

Luego analizando las features agregadas maxstat tiene una alta correlación con statrange, statstd, statsabove100, y totalpercentile por lo tanto podría ser redundante para el modelo. minstat tiene una alta correlación con totalpercentile y statsabove100. statrange tiene una alta correlación con statstd. statabove100 con totalpercentile y totalpercentile con total.

Si analizamos las correlaciones con la variable objetivo, se observa que las variables con mayor correlación positiva son: statsabove100, totalxnoevolves, min stats, total y totalpercentile. Lo cual es interesante ya que totalxnoevolves y totalpercentile tienen correlaciones más altas con islegendary que la variable total original, lo cual sugiere que estas features derivadas podrían ser más útiles para predecir si un Pokémon es legendario, lo que justifica también el feature enginering realizado.

Y la variable evolves que tiene una correlación negativa con totalxno evolves. A continuación los p-values de estas correlaciones y veremos cuales son más significativas para nuestro análisis.

La variable más significativa para el análisis es statsabove100 la cual tiene un alta correlación con total, maxstat,  las variables de combate, height y weight, lo que significa que esta podría representar a estas variables con el menor p-value del dataset por lo tanto decidimos dejar esta variable. totalxnoevolves no tiene una alta correlacion con statsabove100 y tiene una alta significancia por lo tanto la dejamos para el análisis. minstat no la seguiremos considerando ya que tiene una correlación de 0.55 con statsabove100. total, totalpercentile, spatk, maxstat, weight, hp, atk, def, weight, maxstat tampoco las seguiremos considerando ya que tienen una alta correlación con statsabove100 y evolves con totalxnoevolves. Seguimeos dejando speed, height y generationencoded.

Con las variables pre-seleccionadas volvemos a preparar el dataset.

Teniendo el dataset reducido analizaremos ahora la importancia de las características para analizar mejor si vale la pena tener esas features para el entrenamiento del modelo de clasificación. Para ello utilizaremos tres métodos.

El método de anova F-Score detecta diferencia de medias entre clases.

generationencoded es la que menor puntua, seguido de height, las cuales podrían no ser útiles en el análisis.

Mutual information mide la cantidad de información compartida entre la variable y la variable objetivo mediante el calculo de la entropía que mide la incertidubre de una variable.

generationencoded casi no adiciona información al modelo, seguido de height, por lo que estas features podrían ser redundantes.

Considerando todo el análisis previo que hemos hecho y explicado porque decidimos eliminar algunas features del modelo hacemos la selección final de las mismas y preparamos el dataset final.

Dividimos el dataset en conjunto de entrenamiento (80%) y prueba (20%), utilizando estratificación para mantener la proporción de clases.

Como hemos visto en el apartado del análisis de las variables objetivos para la clasificación, hemos identificado que el dataset se encuentra desbalanceado por lo tanto para balancearlo decidimos utilizar una técnica de over sampling SMOTE (Synthetic Minority Oversampling Technique) que lo que hace es generar ejemplos sintéticos de la clase minoritaria para balancear el dataset.

En esta sección aplicaremos cuatro algoritmos de clasificación Regresión Logística, Support Vector Machine (SVM), Árbol de Decisión y K-Nearest Neighbors (KNN) para predecir la variable binaria islegendary.

> Nota importante: considerando que el dataset está desbalanceado con un 90.9% ordinary y 9.1% legendary tendremos que tener en cuenta las métricas apropiadas como: F1-score, Precision, Recall además de Accuracy

Creamos una funcion llamada evaluatemodel la cual utilizaremos para hacer las predicciones, calcular las métricas, imprimir los resultados y la matriz de confusión para cada uno de los modelos que desarrollaremos en esta sección.

La regresión logística es un algoritmo de clasificación que estima la probabilidad de que una variable pertenezca a una clase. Para esto utiliza una función sigmoidea que lo que hace es transformar una combinación lineal de features en una probabilidad entre 0 o 1 donde cada feature tiene un coeficiente.

- Si la probabilidad P > 0.5 la clase es 1.
- Si la probabilidad P ≤ 0.5 la clase 0.

Durante el entrenamiento ajusta los coeficientes para maximizar la probabilidad de clasificar correctamente y utiliza la máxima verosimilitud para ello.

Parámetros:

- C: controla la regularización
- penalty: 'l1' o 'l2' utilizado para evitar el sobreajuste
- classweight='balanced'
- maxiter: número máximo de iteraciones

Para la búsqueda de hiperparámetros configuramos C que controla la fuerza de la regularización, y la regularización l1 y l2, que hace referencia a lasso y ridge que son técnicas de regularización para reducir el sobreajuste y mejorar la generalización.

- Rigde regression lo que hace es penalizar la suma de los cuadrados de los coeficientes. Básicamente calcula la función de pérdida haciendo la sumatoria del cuadrado de los coeficientes.

- Lasso Regression penaliza la suma de los valores absolutos de los coeficientes, añadiendo el valor absoluto a la función de pérdida.

Para esta configuración se utiliza un solver que es un algoritmo que resuelve el problema de optimización, en regresión logística busca los valores de los coeficientes que minimizan la función de pérdida.

También configuramos classweight='balanced que ajusta los pesos de las clases durante el entrenamiento.

Configuramos una función de LogisticRegression como base con un randomstate de 42 y maxiter de 10000. Y para hacer la validación cruzada utilizamos StratifiedKFold que con nsplit sivide los datos en n folds en cada iteración 4 folds para entrenar y uno para validar, 5 veces. Utilizamos shuffle=True que mezcla los datos antes de dividir, evitando sesgos si los datos están desordenados y fijamos la semilla aleatorio en 42 para que los resultados sean siempre reproducibles.

Para la búsqueda del mejor hiperparametro utilizamos la función GridSearchCV que lo que hace es probar todas las combinaciones de hiperparámetros definidos y elige la mejor según la métrica especificada.

Para Linear Regression configuramos el modelo base lrbase, paramgridlr que es el diccionario con las combinaciones a probar, con cv como estrategia de validación cruzada, scoring de f1, njobs -1 utiliza todos los núcleos disponibles en la computadora para paralelizar la búsqueda y returntrainscore True guarda los scores de entrenamiento.

En la validación cruzada nos dió un score de 0.91 en f1 que nos indica que tanto la precisión como el recall están bien balanceados y es consistente en los 5 folds.

Para la evaluación del modelo utilizamos los parámetros que mejor score nos dieron en F1 en la validación cruzada y evaluamos el modelo.

La matriz de confusión muestra 175 verdaderos negativos, 11 falsos positivos, 2 falsos negativos y 17 verdaderos positivos, indicando que el modelo tiene buen recall, con una precisión 0.6071 indicando que un 60.71% de las predicciones como legendarios son correctas, mientras que el recall de 0.8947 indica que captura el 89.47% de los legendarios reales. El F1-score de 0.7234 balancea ambas métricas, el cual es un resultado moderado para un problema de clasificación que considero que se puede mejorar, por eso analizaremos el umbral de decisión que por defecto es 0.5, que quizás no es el óptimo y nuestro modelo pueda mejorar más.

Ajustamos el umbral de decisión que por defecto es 0.5 pero puede no ser óptimo en datasets desbalanceados. Obtenemos las probabilidades con predictproba, calculamos la curva precision-recall con precisionrecallcurve para diferentes umbrales, encontramos el threshold que maximiza el F1-score y aplicamos este umbral óptimo para mejorar el balance entre precision y recall.

El threshold óptimo encontrado fue de 0.839, mucho más alto que el valor de 0.5 por defecto, lo que significa que el modelo solo clasifica como legendario cuando tiene mayor certeza.

El F1-score mejoró de 0.7234 a 0.7500 después del threshold tuning, indicando que el ajuste del umbral optimizó el balance entre precision y recall para el dataset desbalanceado.

En este modelo el feature speed no tiene importancia, el cual se podría eliminar y luego evaluar de nuevo el modelo, aunque para este análisis preferimos dejarlo así porque queremos comparar diferentes algoritmos.

SVM es un algoritmo de clasificación que lo que hace es encontrar un hiperplano óptimo que separe las clases maximizando el margen entre ellas. Para esto utiliza vectores de soporte que son los puntos más cercanos al hiperplano de cada clase que definen la frontera de decisión entre estos.

- Si un punto está de un lado del hiperplano pertenece a la clase 1.
- Si está del otro lado pertenece a la clase 0.

Durante el entrenamiento el algoritmo busca el hiperplano que tenga el mayor margen posible entre las clases, lo cual ayuda a generalizar mejor a nuevos datos. Cuando las clases no son linealmente separables, utiliza kernels como RBF que transforman los datos a un espacio de mayor dimensión donde sí se pueden separar linealmente.

Parámetros:

- C: controla el trade-off entre maximizar el margen y minimizar errores de clasificación
- kernel: 'rbf', 'linear', 'poly' utilizado para transformar los datos a espacios de mayor dimensión
- gamma: parámetro del kernel RBF que controla la influencia de cada punto de entrenamiento
- classweight='balanced': ajusta los pesos de las clases para manejar desbalance

Para la búsqueda de hiperparámetros configuramos C que controla el trade-off entre maximizar el margen y minimizar los errores de clasificación, y los kernels 'rbf', 'linear' y 'poly' que son funciones que transforman los datos a espacios de mayor dimensión donde las clases pueden separarse linealmente.

- Kernel RBF utiliza funciones de base radial para crear fronteras de decisión no lineales y complejas, transformando los datos mediante una función gaussiana.

- Kernel Linear busca un hiperplano óptimo en el espacio original de los datos, separando las clases mediante una línea recta o plano.

- Kernel Poly utiliza funciones polinomiales para transformar los datos, permitiendo separaciones curvas mediante combinaciones polinomiales de las características.

Configuramos gamma que es un parámetro que controla la influencia de cada punto de entrenamiento en la frontera de decisión, donde valores altos crean fronteras más complejas y valores bajos fronteras más suaves. Configuramos una función de SVC como base con un randomstate de 42 y probability=True.

Para Support Vector Machine configuramos el modelo base svmbase, paramgridsvm que es el diccionario con las combinaciones a probar, con cv  para la validación cruzada, scoring de f1, njobs -1 para utilizar todos los núcleos disponibles en la computadora para paralelizar la búsqueda y verbose 0 para que no muestre mensajes durante la búsqueda.

Utilizamos los parametros con el que obtuvimos el mejor score en la validación cruzada para evaluar el modelo.

La matriz de confusión muestra 178 verdaderos negativos, 8 falsos positivos, 1 falso negativo y 18 verdaderos positivos, que nos indica que el modelo tiene excelente recall, con una precisión de 0.6923 que significa que 69.23% de las predicciones como legendarios son correctas, mientras que el recall de 0.9474 indica que captura el 94.74% de los legendarios reales.

El F1-score de 0.8000 balancea ambas métricas, el cual es un resultado muy bueno para un problema de clasificación con clases desbalanceadas, mejorando significativamente respecto a la regresión logística.

El modelo tiene un accuracy en test de 0.9561 que es superior al de entrenamiento 0.9464, lo que indica buena generalización. Por eso analizaremos el umbral de decisión que por defecto es 0.5, que quizás no es el óptimo y nuestro modelo pueda mejorar más.

Para el threshold tuning ajustamos el umbral de decisión que por defecto es 0.5 pero puede no ser óptimo en datasets desbalanceados. Obtenemos las probabilidades con predictproba, calculamos la curva precision-recall con precisionrecallcurve para diferentes umbrales, encontramos el threshold que maximiza el F1-score y aplicamos este umbral óptimo para mejorar el balance entre precision y recall.

El threshold óptimo encontrado fue de 0.570, un poco más alto que el valor de 0.5 por defecto, lo que significa que el modelo requiere un poco más de certeza para clasificar como legendario. El F1-score se mantuvo en 0.8000 después del threshold tuning, indicando que el threshold por defecto ya era cercano al óptimo para este modelo, lo que demuestra que SVM tiene un buen balance entre precision y recall sin necesidad de ajustes significativos del umbral.

El árbol de decisión es un algoritmo de clasificación que lo que hace es dividir recursivamente el dataset en subconjuntos más pequeños basándose en las features que mejor separan las clases. Para esto utiliza nodos que representan decisiones sobre las features y hojas que representan las clases finales.

- Si se cumple una condición en un nodo se sigue por una rama.
- Si no se cumple se sigue por otra rama hasta llegar a una hoja que indica la clase.

Durante el entrenamiento construye el árbol eligiendo en cada nodo la feature que mejor separa las clases, utilizando métricas como la entropía o el índice Gini. El proceso continúa hasta que se alcanza un criterio de parada como la profundidad máxima o el número mínimo de muestras por hoja.

Parámetros:

- maxdepth: profundidad máxima del árbol para evitar sobreajuste
- minsamplessplit: número mínimo de muestras requeridas para dividir un nodo
- minsamplesleaf: número mínimo de muestras requeridas en una hoja
- criterion: 'gini' o 'entropy' utilizado para medir la calidad de la división
- classweight='balanced': ajusta los pesos de las clases para manejar desbalance

Para la búsqueda de hiperparámetros configuramos maxdepth que controla la profundidad máxima del árbol limitando cuántos niveles de decisiones puede tener, y minsamplessplit y minsamplesleaf que son técnicas de regularización para reducir el sobreajuste y mejorar la generalización.

- minsamplessplit lo que hace es establecer el número mínimo de muestras requeridas para dividir un nodo interno, penalizando divisiones sobre grupos pequeños de datos calculando la función de pérdida considerando el tamaño mínimo del nodo.

- minsamplesleaf establece el número mínimo de muestras que debe tener un nodo hoja, añadiendo una restricción adicional a la función de pérdida para evitar hojas con muy pocos ejemplos.

Para esta configuración se utiliza un criterio que es una medida que evalúa la calidad de una división en el árbol, ya que en árboles de decisión se busca los valores de los atributos que maximizan la separación entre clases minimizando de esa forma la impureza.

Configuramos ccpalpha que es un parámetro de poda que penaliza la complejidad del árbol, reduciendo asi el sobreajuste mediante la eliminación de ramas que no aportan suficiente información.

También configuramos criterion con 'gini' y 'entropy' que son medidas de impureza, donde gini calcula la probabilidad de clasificar incorrectamente un elemento y entropy mide la cantidad de información necesaria para clasificar correctamente. classweight='balanced' que ajusta los pesos de las clases durante el entrenamiento.

Y utilizamos una función de DecisionTreeClassifier como base con un randomstate de 42.

Para Árbol de Decisión configuramos el modelo base dtbase, paramgriddt que es el diccionario con las combinaciones a probar, con cv para la validación cruzada, scoring con un diccionario que incluye recall, precision y f1, configuramos refit "f1" para que entrene el modelo final usando f1 como métrica principal, y njobs -1 para utilizar todos los núcleos disponibles en la computadora para paralelizar la búsqueda.

Utilizamos los parametros con el que obtuvimos el mejor score en la validación cruzada para evaluar el modelo.

La matriz de confusión muestra 180 verdaderos negativos, 6 falsos positivos, 3 falsos negativos y 16 verdaderos positivos, indicando que el modelo tiene buen recall, con una precisión de 0.7273, lo cual nos indica que un 72.73% de las predicciones como legendarios son correctas, mientras que el recall de 0.8421 indica que captura el 84.21% de los legendarios reales. El F1-score de 0.7805 balancea ambas métricas, el cual es un resultado bueno para un problema de clasificación. Sin embargo, el accuracy en entrenamiento de 1.0000 sugiere posible sobreajuste, aunque el accuracy en test de 0.9561 es similar al de otros modelos, lo que indica que la regularización aplicada funcionó correctamente. El modelo tiene la mejor precisión entre los modelos evaluados, con solo 6 falsos positivos, lo cual es una mejora importante.

A continuación graficamos los primeros 3 niveles del árbol de decisión.

Para el árbol de decisión las features elegidas toman importancia, resultado que concuerda con las respuestas obtenidas.

KNN es un algoritmo de clasificación que lo que hace es clasificar un punto basándose en la clase de sus k vecinos más cercanos en el espacio de features. Para esto utiliza una medida de distancia, generalmente euclidiana, para encontrar los puntos de entrenamiento más cercanos al punto a clasificar.

- Si la mayoría de los k vecinos más cercanos pertenecen a la clase 1, el punto se clasifica como clase 1.
- Si la mayoría pertenecen a la clase 0, se clasifica como clase 0.

Durante la clasificación calcula las distancias entre el punto nuevo y todos los puntos de entrenamiento, selecciona los k más cercanos y asigna la clase más frecuente entre ellos. Es un algoritmo basado en instancias que no requiere entrenamiento previo, ya que almacena todos los datos de entrenamiento y realiza la clasificación cuando se necesita predecir.

Parámetros:

- nneighbors: número de vecinos a considerar para la clasificación
- weights: 'uniform' o 'distance' para dar igual peso o más peso a vecinos cercanos
- metric: tipo de distancia a utilizar, generalmente 'euclidean' o 'manhattan'
- algorithm: algoritmo utilizado para encontrar los vecinos más cercanos

Para la búsqueda de hiperparámetros configuramos nneighbors que controla el número de vecinos más cercanos a considerar para clasificar un punto, y las métricas de distancia 'euclidean', 'manhattan' y 'minkowski' que son técnicas para medir la similitud entre puntos y mejorar la clasificación.

- Euclidean distance lo que hace es calcular la distancia en línea recta entre dos puntos en el espacio multidimensional, básicamente calcula la función de distancia haciendo la raíz cuadrada de la sumatoria de las diferencias al cuadrado de cada coordenada.

- Manhattan distance penaliza la suma de los valores absolutos de las diferencias entre coordenadas, añadiendo el valor absoluto a la función de distancia.

Para esta configuración se utiliza un algoritmo que es un método basado en instancias que no requiere entrenamiento previo, dado que KNN busca los k puntos de entrenamiento más cercanos al punto a clasificar, utilizando una medida de distancia para encontrar a los vecinos.

También configuramos weights que determina cómo se ponderan los votos de los vecinos, donde 'uniform' da igual peso a todos los vecinos y 'distance' da más peso a los vecinos más cercanos y p que es el parámetro para la distancia de Minkowski, donde p=1 corresponde a Manhattan y p=2 corresponde a Euclidean.

Luego llamamos a la función de KNeighborsClassifier como base.

Para K-Nearest Neighbors configuramos el modelo base knnbase, paramgridknn que es el diccionario con las combinaciones a probar, con cv para la validación cruzada, con scoring de recall, y njobs -1 para utilizar todos los núcleos disponibles en la computadora para paralelizar la búsqueda.

Utilizamos los parametros con el que obtuvimos el mejor score en la validación cruzada para evaluar el modelo.

La matriz de confusión muestra 177 verdaderos negativos, 9 falsos positivos, 2 falsos negativos y 17 verdaderos positivos, lo cual indica que el modelo tiene un buen recall, con una precisión de 0.6538, donde 65.38% de las predicciones como legendarios son correctas. El recall de 0.8947 indica que captura el 89.47% de los legendarios reales.

El F1-score de 0.7556 balancea ambas métricas, el cual es un resultado bueno para un problema de clasificación. El accuracy en entrenamiento de 1.0000 sugiere posible sobreajuste, aunque el accuracy en test de 0.9463 es razonable.

A continuación compararemos los modelos mencionados y sus métricas.

Para comparar los modelos de una manera adecuada primero graficamos las distintas matrices de confusión y luego las métricas obtenidas.

SVM(tunned)

El modelo final del SVM tunned es el modelo que mejor predice la clasificación. Su matriz de confusión muestra TP=18, FN=1, TN=178 y FP=8, lo cual indica que detecta 18 de los 19 legendarios con un recall de 0.9474, con una precision de 0.6923, esto resulta en un F1-Score de 0.8.

Considerando la optimización que hace el algoritmo Support Vector Machine es utilizar un criterio de decisión basado en la minimización de la hinge loss regularizada que lo que hace es penalizar solo las predicciones cercanas al margen o incorrectas, lo cual permite más margen al modelo evitando el sobreajuste. Y al aplicar hiperparámetros ajustados mediante GridSearchCV y un kernel no lineal como RBF, el modelo logra capturar relaciones complejas entre las variables sin sacrificar el control sobre la complejidad o llegar a sobreajustarse.

En el análisis ROC alcanza el un AUC de 0.939, lo cual indica que independientemente del umbral elegido, el SVM tiene una capacidad de discriminación del 93.9% para separar correctamente Pokémons legendarios de ordinarios.

Regresión Logística (tuned)

La matriz de confusión del modelo de Regresión Logística muestra TP=17, FN=2, TN=175 y FP=11, lo cual indica que detecta 17 de los 19 legendarios con un recall de 0.7895, y una precision de 0.7143, que resulta en un F1-Score de 0.7500.

El algoritmo de regresión logística lo que hace es utilizar una frontera de decisión lineal mediante la minimización de la log-loss, lo que le permite aprender relaciones lineales entre las variables. Cuando la separación entre las clases no es lineal o hay solapamiento de features el modelo puede desplazar el umbral de decisión en el cual vimos que se desplazó de 0.5 a 0.839 para capturar más positivos. Esta respuesta incrementó el recall a costo de generar más falsos positivos. Luego al hacer el threshold tunning el F1-Score mejoró de 0.7234 a 0.7500, optimizando el balance entre precision y recall para el dataset desbalanceado.

Árbol de Decisión

El modelo del árbol de decisión es el clasificador más conservador del grupo ya que su matriz de confusión muestra TP=16, FN=3, TN=180 y FP=6, detectando 16 de los 19 legendarios con un recall de 0.8421, y una precision de 0.7273, que resulta en un F1-Score de 0.7805.

El algoritmo de árbol de decisión construye el árbol eligiendo en cada nodo la mejor feature que separa las clases, utilizando métricas como la entropía o el índice de Gini mediante GridSearchCV, que permite generar particiones que favorecen la clase mayoritaria cuando existe desbalance. Por este motivo este es el único modelo que es robusto frente al desbalanceo de clases.

En la tabla comparativa se visualiza que el modelo alcanza un accuracy de entrenamiento de 1 que podría entenderse como una alta varianza y posible sobreajuste, que puede deberse a que el árbol puede memorizar reglas muy específicas del conjunto de entrenamiento. Aunque generaliza razonablemente bien en test con un accuracy de 0.9561, el modelo prefiere ser más conservador y reducir los falsos positivos, lo cual hace que tenga la precision más alta pero el recall más bajo comparado con los otros modelos. Y en el análisis ROC tiene un AUC de 0.905 que indica una buena capacidad de discriminación para separar correctamente Pokémons legendarios de ordinarios.

KNN

La matriz de confusión del modelo de KNN muestra TP=17, FN=2, TN=177 y FP=9, detectando 17 de los 19 legendarios con un recall de 0.8947, y una precision de 0.6538, que resulta en un F1-Score de 0.7556.

Esto se explica por como funciona ya que el algoritmo KNN utiliza un método no paramétrico basado en distancias donde la predicción depende del voto mayoritario de los k vecinos más cercanos, que se optimiza mediante GridSearchCV, permitiendo capturar relaciones locales en el espacio de features Cuando el espacio tiene muchas dimensiones, escalas heterogéneas o ruido, la noción de "vecindad" se degrada por el fenómeno conocido como curse of dimensionality, generando errores en las fronteras entre clases. Asimismo, su accuracy de entrenamiento igual a 1 es consistente con la capacidad del modelo de memorizar el conjunto de entrenamiento, especialmente con valores pequeños de k, lo que explica por qué no supera al SVM regularizado en el conjunto de test, donde alcanza un accuracy de 0.9463. Los 9 falsos positivos reducen su precision a 0.6538, siendo este el valor más bajo entre todos los modelos evaluados.

Iniciamos este estudio con el objetivo de desarrollar un modelo de clasificación de Pokémons, utilizando el dataset "Data of 1015 Pokémons" de Kaggle. Antes de definir qué tipo de clasificación íbamos a llevar a cabo en este proyecto realizamos un análisis exploratorio de los datos donde estudiamos las variables de combates, las cuales vimos que tenían outliers que podían ser causados por un tipo raro de pokémons o quizás los legendarios, lo cual fue el primer patrón que vimos en el dataset al hacer el análisis, luego al analizar las variables categóricas visualizamos comportamientos extraños de acuerdo al type1 y type2 los cuales analizamos para un posible análisis de multiclase, el cual fue descartado al analizar la variable evolvesfrom donde nos dimos cuenta de que no todos los pokémones evolucionaban y curiosamente los que tenían estadísticas más altas no evolucionaban, por lo tanto podría haber un patrón muy marcado en el dataset acerca de si es legendario o no. Por esta razón luego definimos a nuestra variable objetivo islegendary para saber si un pokemon es legendario o no, con la finalidad de poder clasificarlos teniendo en cuenta eso.

Al analizar esta variable binaria nos dimos cuenta que estaba desbalanceada con aproximadamente 90.9% de Pokémones ordinarios y solo 9.1% de legendarios. Analizamos la relación con las variables numéricas y nos dimos cuenta que sí podría funcionar esta variable objetivo ya que esta tenía distribuciones diferentes de las demás variables del dataset, y mediante el test de Mann-Whitney pudimos comprobar que son linealmente independientes con distribuciones diferentes corroborando con el test chi-cuadrado que hay una asociación con las variables categóricas.

Luego hicimos el procesado de los datos donde codificamos las variables categóricas e hicimos un feature engineering agregando variables que podrían ser útiles para el análisis, preparamos el dataset final estandarizando los datos, haciendo un análisis de multicolinealidad mediante la matriz de correlación y descartando las variables que estaban muy correlacionadas y dando importancia a las que tenían buena correlación con la variable objetivo, hicimos un análisis de importancia de las características utilizando ANOVA F-score y mutual information para ver cuáles eran las variables que compartían más información con la variable objetivo y finalmente seleccionamos los features finales y dividimos el dataset en train test, luego hicimos un oversampling de los datos de train para manejar el desbalance de clases que vimos.

Finalmente diseñamos y evaluamos cuatro algoritmos: Regresión Logística, SVM, Árbol de Decisión y KNN, con optimización de hiperparámetros mediante GridSearchCV y validación cruzada estratificada.

El modelo final del SVM tuned es el modelo que mejor predice la clasificación de pokémones legendarios o ordinarios ya que alcanza el F1-Score más alto con 0.8. Su matriz de confusión refleja que detecta 18 de los 19 legendarios con un recall de 0.9474 manteniendo los falsos positivos controlados con una precisión de 0.6923. El Árbol de Decisión fue el más conservador con la precisión más alta y el recall más bajo, mientras que KNN y Regresión Logística quedaron en el medio de estos.

En resumen, este estudio demuestra que las estadísticas de combate, especialmente transformadas en features como statsabove100 y totalxnoevolves, son buenos predictores para distinguir Pokémones legendarios de ordinarios. Los legendarios ocupan una región distinguible en el espacio de features, caracterizada por valores altos en múltiples estadísticas. El SVM optimizado es una buena solución para resolver problemas de clasificación desbalanceada, el cual en este estudio ofreció el mejor balance entre detectar legendarios y minimizar falsos positivos.
